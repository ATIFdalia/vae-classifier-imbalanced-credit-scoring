{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aec1fe07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 18.128470605214435\n",
      "Epoch 2, Loss: 14.313530550638834\n",
      "Epoch 3, Loss: 13.486757625579834\n",
      "Epoch 4, Loss: 13.083155586242675\n",
      "Epoch 5, Loss: 12.778535640716553\n",
      "Epoch 6, Loss: 12.588304039001464\n",
      "Epoch 7, Loss: 12.473267387390136\n",
      "Epoch 8, Loss: 12.390573603312175\n",
      "Epoch 9, Loss: 12.215712656656901\n",
      "Epoch 10, Loss: 12.14114464823405\n",
      "Epoch 11, Loss: 12.212037745157877\n",
      "Epoch 12, Loss: 11.997419469197592\n",
      "Epoch 13, Loss: 12.093397855122884\n",
      "Epoch 14, Loss: 12.060405234018962\n",
      "Epoch 15, Loss: 12.02161243311564\n",
      "Epoch 16, Loss: 12.037288511912028\n",
      "Epoch 17, Loss: 11.926370989481608\n",
      "Epoch 18, Loss: 11.901849361419679\n",
      "Epoch 19, Loss: 11.89214650217692\n",
      "Epoch 20, Loss: 11.926893332163493\n",
      "Epoch 21, Loss: 11.818083700815837\n",
      "Epoch 22, Loss: 11.846307713826498\n",
      "Epoch 23, Loss: 11.796888298034668\n",
      "Epoch 24, Loss: 11.833888449350994\n",
      "Epoch 25, Loss: 11.934447603861491\n",
      "Epoch 26, Loss: 11.77062213007609\n",
      "Epoch 27, Loss: 11.748546326955159\n",
      "Epoch 28, Loss: 11.732370301564535\n",
      "Epoch 29, Loss: 11.86362199529012\n",
      "Epoch 30, Loss: 11.703475152333578\n",
      "Epoch 31, Loss: 11.742795051574706\n",
      "Epoch 32, Loss: 11.772276023864746\n",
      "Epoch 33, Loss: 11.73756516011556\n",
      "Epoch 34, Loss: 11.732312513987223\n",
      "Epoch 35, Loss: 11.638953834533691\n",
      "Epoch 36, Loss: 11.763093194325766\n",
      "Epoch 37, Loss: 11.7008173828125\n",
      "Epoch 38, Loss: 11.642988417307535\n",
      "Epoch 39, Loss: 11.736863156636556\n",
      "Epoch 40, Loss: 11.71916854095459\n",
      "Epoch 41, Loss: 11.6730760790507\n",
      "Epoch 42, Loss: 11.659078154246012\n",
      "Epoch 43, Loss: 11.636088483174643\n",
      "Epoch 44, Loss: 11.629941539764404\n",
      "Epoch 45, Loss: 11.61766246287028\n",
      "Epoch 46, Loss: 11.674495558420817\n",
      "Epoch 47, Loss: 11.62970795059204\n",
      "Epoch 48, Loss: 11.60859162012736\n",
      "Epoch 49, Loss: 11.673151907602946\n",
      "Epoch 50, Loss: 11.61288921737671\n",
      "VAE Classifier AUC on Test Set: 0.746943426186836\n",
      "Type II Error (False Negative Rate): 0.43488194973343486\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Load data\n",
    "input_csv = 'path/to/your/data.csv' # Replace with your data path\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "continuous_features = ['LIMIT_BAL', 'AGE', 'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', \n",
    "                       'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6', 'PAY_AMT1', \n",
    "                       'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']\n",
    "categorical_features = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', \n",
    "                        'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "class_col = 'default.payment.next.month'\n",
    "\n",
    "# Preprocess data\n",
    "X_continuous = df[continuous_features].values\n",
    "X_categorical = pd.get_dummies(df[categorical_features], drop_first=True).values\n",
    "X = np.hstack([X_continuous, X_categorical])\n",
    "y = df[class_col].values\n",
    "\n",
    "# Standardize continuous features\n",
    "scaler = StandardScaler()\n",
    "X_continuous = scaler.fit_transform(X_continuous)\n",
    "\n",
    "# Combine continuous and one-hot encoded categorical features\n",
    "X = np.hstack([X_continuous, X_categorical])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors and DataLoader\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
    "\n",
    "# Define VAE with integrated classifier\n",
    "class VAEClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, output_dim):\n",
    "        super(VAEClassifier, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim * 2)  # latent_dim * 2 for mean and log-variance\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, logvar = h.chunk(2, dim=-1)\n",
    "        return mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "    def classify(self, z):\n",
    "        return self.classifier(z)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), self.classify(z), mu, logvar\n",
    "\n",
    "def loss_function(recon_x, x, pred_y, y, mu, logvar, class_weights, alpha):\n",
    "    BCE = nn.functional.binary_cross_entropy(pred_y, y, weight=class_weights[y.long()].view(-1, 1), reduction='sum')\n",
    "    MSE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return MSE + KLD + alpha * BCE\n",
    "\n",
    "def train_vae_classifier(model, dataloader, optimizer, class_weights, alpha, epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0\n",
    "        for data, target in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, pred_y, mu, logvar = model(data)\n",
    "            loss = loss_function(recon_batch, data, pred_y, target, mu, logvar, class_weights, alpha)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print(f'Epoch {epoch+1}, Loss: {train_loss / len(dataloader.dataset)}')\n",
    "\n",
    "# Parameters for model\n",
    "input_dim = X_train.shape[1]\n",
    "latent_dim = 12  # You can change this value based on your experiment\n",
    "output_dim = 1  # Binary classification\n",
    "alpha = 4.0  # You can change this value based on your experiment\n",
    "\n",
    "# Initialize and train the VAEClassifier\n",
    "vae_classifier = VAEClassifier(input_dim, latent_dim, output_dim)\n",
    "optimizer = optim.Adam(vae_classifier.parameters(), lr=1e-3)\n",
    "\n",
    "train_vae_classifier(vae_classifier, train_dataloader, optimizer, class_weights, alpha)\n",
    "\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "with torch.no_grad():\n",
    "    mu_test, logvar_test = vae_classifier.encode(X_test_tensor)\n",
    "    latent_test = vae_classifier.reparameterize(mu_test, logvar_test)\n",
    "    pred_y_test = vae_classifier.classify(latent_test).numpy().squeeze()\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = (pred_y_test > 0.5).astype(int)\n",
    "auc = roc_auc_score(y_test, pred_y_test)\n",
    "\n",
    "print(f'VAE Classifier AUC on Test Set: {auc}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "type_II_error = fn / (fn + tp)\n",
    "\n",
    "print(f'Type II Error (False Negative Rate): {type_II_error}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa882f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
